{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/rottentomatoes/rotten_tomatoes_movies.csv\n",
      "/kaggle/input/rottentomatoes/rotten_tomatoes_critic_reviews.csv\n",
      "/kaggle/input/glove-embeddings/glove.6B.100d.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Importing the Datasets\n",
    "import pandas as pd\n",
    "Movies = pd.read_csv(\"/kaggle/input/rottentomatoes/rotten_tomatoes_movies.csv\")\n",
    "Reviews = pd.read_csv(\"/kaggle/input/rottentomatoes/rotten_tomatoes_critic_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>critic_name</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher_name</th>\n",
       "      <th>review_type</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Ben McEachen</td>\n",
       "      <td>False</td>\n",
       "      <td>Sunday Mail (Australia)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>3.5/5</td>\n",
       "      <td>2010-02-09</td>\n",
       "      <td>Whether audiences will get behind The Lightnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>m/0878835</td>\n",
       "      <td>Erik Childress</td>\n",
       "      <td>False</td>\n",
       "      <td>eFilmCritic.com</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>3/4</td>\n",
       "      <td>2010-01-31</td>\n",
       "      <td>Holofcener always gives us more to chew on tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>m/10</td>\n",
       "      <td>Scott Weinberg</td>\n",
       "      <td>False</td>\n",
       "      <td>eFilmCritic.com</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>4/5</td>\n",
       "      <td>2002-07-25</td>\n",
       "      <td>Obvious but entertaining portrayal of midlife ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>m/1000013-12_angry_men</td>\n",
       "      <td>Steve Rhodes</td>\n",
       "      <td>False</td>\n",
       "      <td>Internet Reviews</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>4/4</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>In a time of bloated when special effects have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>m/1000079-20000_leagues_under_the_sea</td>\n",
       "      <td>Dragan Antulov</td>\n",
       "      <td>False</td>\n",
       "      <td>rec.arts.movies.reviews</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>7/10</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>[The] embodiment of Disney at his best -- fami...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      rotten_tomatoes_link     critic_name  top_critic  \\\n",
       "3                                m/0814255    Ben McEachen       False   \n",
       "153                              m/0878835  Erik Childress       False   \n",
       "292                                   m/10  Scott Weinberg       False   \n",
       "316                 m/1000013-12_angry_men    Steve Rhodes       False   \n",
       "369  m/1000079-20000_leagues_under_the_sea  Dragan Antulov       False   \n",
       "\n",
       "              publisher_name review_type review_score review_date  \\\n",
       "3    Sunday Mail (Australia)       Fresh        3.5/5  2010-02-09   \n",
       "153          eFilmCritic.com       Fresh          3/4  2010-01-31   \n",
       "292          eFilmCritic.com       Fresh          4/5  2002-07-25   \n",
       "316         Internet Reviews       Fresh          4/4  2000-01-01   \n",
       "369  rec.arts.movies.reviews       Fresh         7/10  2000-01-01   \n",
       "\n",
       "                                        review_content  \n",
       "3    Whether audiences will get behind The Lightnin...  \n",
       "153  Holofcener always gives us more to chew on tha...  \n",
       "292  Obvious but entertaining portrayal of midlife ...  \n",
       "316  In a time of bloated when special effects have...  \n",
       "369  [The] embodiment of Disney at his best -- fami...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Dropping rows with NA values\n",
    "Reviews = Reviews.dropna()\n",
    "\n",
    "# Dropping Duplicates so that there is only one entry per Movie.\n",
    "Reviews = Reviews.drop_duplicates(subset=['rotten_tomatoes_link'], keep = \"first\")\n",
    "Reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>critics_consensus</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Percy Jackson &amp; the Olympians: The Lightning T...</td>\n",
       "      <td>Though it may seem like just another Harry Pot...</td>\n",
       "      <td>3.5/5</td>\n",
       "      <td>Whether audiences will get behind The Lightnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m/0878835</td>\n",
       "      <td>Please Give</td>\n",
       "      <td>Nicole Holofcener's newest might seem slight i...</td>\n",
       "      <td>3/4</td>\n",
       "      <td>Holofcener always gives us more to chew on tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m/10</td>\n",
       "      <td>10</td>\n",
       "      <td>Blake Edwards' bawdy comedy may not score a pe...</td>\n",
       "      <td>4/5</td>\n",
       "      <td>Obvious but entertaining portrayal of midlife ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m/1000013-12_angry_men</td>\n",
       "      <td>12 Angry Men (Twelve Angry Men)</td>\n",
       "      <td>Sidney Lumet's feature debut is a superbly wri...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>In a time of bloated when special effects have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m/1000079-20000_leagues_under_the_sea</td>\n",
       "      <td>20,000 Leagues Under The Sea</td>\n",
       "      <td>One of Disney's finest live-action adventures,...</td>\n",
       "      <td>7/10</td>\n",
       "      <td>[The] embodiment of Disney at his best -- fami...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    rotten_tomatoes_link  \\\n",
       "0                              m/0814255   \n",
       "1                              m/0878835   \n",
       "2                                   m/10   \n",
       "3                 m/1000013-12_angry_men   \n",
       "4  m/1000079-20000_leagues_under_the_sea   \n",
       "\n",
       "                                         movie_title  \\\n",
       "0  Percy Jackson & the Olympians: The Lightning T...   \n",
       "1                                        Please Give   \n",
       "2                                                 10   \n",
       "3                    12 Angry Men (Twelve Angry Men)   \n",
       "4                       20,000 Leagues Under The Sea   \n",
       "\n",
       "                                   critics_consensus review_score  \\\n",
       "0  Though it may seem like just another Harry Pot...        3.5/5   \n",
       "1  Nicole Holofcener's newest might seem slight i...          3/4   \n",
       "2  Blake Edwards' bawdy comedy may not score a pe...          4/5   \n",
       "3  Sidney Lumet's feature debut is a superbly wri...          4/4   \n",
       "4  One of Disney's finest live-action adventures,...         7/10   \n",
       "\n",
       "                                      review_content  \n",
       "0  Whether audiences will get behind The Lightnin...  \n",
       "1  Holofcener always gives us more to chew on tha...  \n",
       "2  Obvious but entertaining portrayal of midlife ...  \n",
       "3  In a time of bloated when special effects have...  \n",
       "4  [The] embodiment of Disney at his best -- fami...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging two Dataframes\n",
    "newDf = pd.merge(Movies, Reviews, on = \"rotten_tomatoes_link\", how = \"inner\") \n",
    "\n",
    "# Dropping columns which are not required\n",
    "newDf.drop(['movie_info','content_rating','genres','directors','authors','actors','original_release_date','tomatometer_top_critics_count','tomatometer_fresh_critics_count','tomatometer_rotten_critics_count','critic_name','top_critic','publisher_name','review_type','review_date','streaming_release_date','runtime','production_company','tomatometer_status','tomatometer_rating','tomatometer_count','audience_status','audience_rating','audience_count'],axis=1,inplace=True)\n",
    "newDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '10', '100', '20', '3', '4', '5', '6', '7', '8', '9', 'A',\n",
       "       'A-', 'B', 'B+', 'B-', 'C', 'C+', 'C-', 'D', 'D+', 'D-', 'F'],\n",
       "      dtype='<U3')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching unique rating scale to generalize the rating\n",
    "ratingList = np.unique(newDf.review_score).tolist()\n",
    "max_score = []\n",
    "for r in range(len(ratingList)):\n",
    "    temp = ratingList[r].split(\"/\")\n",
    "    if len(temp) > 1:\n",
    "        max_score.append(temp[1])\n",
    "    elif len(temp) == 1:\n",
    "        max_score.append(temp)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "max_score = [i for b in map(lambda x:[x] if not isinstance(x, list) else x, max_score) for i in b]\n",
    "uniq_score = np.unique(max_score)\n",
    "uniq_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalizing the all the review ratings to standard scale of 5 being highest and 0 being least.\n",
    "rating = newDf.review_score.tolist()\n",
    "genrat = []\n",
    "for r in range(len(rating)):\n",
    "    temp = rating[r].split(\"/\")\n",
    "    #print(len(temp))\n",
    "    if len(temp) > 1:\n",
    "        if temp[1] == '10':\n",
    "            score = round(float(temp[0]) / 2)\n",
    "            genrat.append(score)\n",
    "        elif temp[1] == '100':\n",
    "            score = round(float(temp[0]) / 20)\n",
    "            genrat.append(score)\n",
    "        elif temp[1] == '20':\n",
    "            score = round(float(temp[0]) / 4)\n",
    "            genrat.append(score)\n",
    "        elif temp[1] == '3':\n",
    "            score = round(float(temp[0]) * 5 / 3)\n",
    "            genrat.append(score)\n",
    "        elif temp[1] == '4':\n",
    "            score = round(float(temp[0]) * 5 / 4)\n",
    "            genrat.append(score)\n",
    "        elif temp[1] == '5':\n",
    "            score = round(float(temp[0]))\n",
    "            genrat.append(score)\n",
    "        elif temp[1] == '6':\n",
    "            score = round(float(temp[0]) * 5 / 6)\n",
    "            genrat.append(score)\n",
    "        elif temp[1] == '7':\n",
    "            score = round(float(temp[0]) * 5 / 7)\n",
    "            genrat.append(score)\n",
    "        elif temp[1] == '8':\n",
    "            score = round(float(temp[0]) * 5 / 8)\n",
    "            genrat.append(score)\n",
    "        elif temp[1] == '9':\n",
    "            score = round(float(temp[0]) * 5 / 9)\n",
    "            genrat.append(score)\n",
    "    elif len(temp) == 1:\n",
    "        if temp == 'A-' or 'A' or 'A+':\n",
    "            score = 5\n",
    "            genrat.append(score)\n",
    "        elif temp == 'B-' or 'B' or 'B+':\n",
    "            score = 4\n",
    "            genrat.append(score)\n",
    "        elif temp == 'C-' or 'C' or 'C+':\n",
    "            score = 3\n",
    "            genrat.append(score)\n",
    "        elif temp == 'D-' or 'D' or 'D+':\n",
    "            score = 2\n",
    "            genrat.append(score)\n",
    "        elif temp == 'F-' or 'F' or 'F+':\n",
    "            score = 1\n",
    "            genrat.append(score)\n",
    "        else :\n",
    "            score = temp\n",
    "            genrat.append(score)\n",
    "        \n",
    "           \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDf['Standard_rating'] = genrat\n",
    "#newDf = newDf[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Preprocessing of Data\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "#from spacy.lang.en.stop_words import STOP_WORDS\n",
    "#nlp = en_core_web_sm.load()\n",
    "nlp = spacy.load(\"en_core_web_sm\",disable=[\"tagger\", \"parser\"])\n",
    "def preprocess(text):\n",
    "    # TODO: Replace the next line with your own code.\n",
    "    doc = nlp(text)\n",
    "    token_list = []\n",
    "    for token in doc:\n",
    "        if token.is_stop == False and token.lemma_.isalpha() and len(token) > 3:\n",
    "            token_list.append(token.lemma_)\n",
    "    return(token_list)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "'''newDf['PreProcessedReview'] = None\n",
    "for i in range(len(newDf)):\n",
    "    newDf['PreProcessedReview'][i] = \" \".join(preprocess(newDf['review_content'][i]))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>critics_consensus</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_content</th>\n",
       "      <th>Standard_rating</th>\n",
       "      <th>PreProcessedReview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Percy Jackson &amp; the Olympians: The Lightning T...</td>\n",
       "      <td>Though it may seem like just another Harry Pot...</td>\n",
       "      <td>3.5/5</td>\n",
       "      <td>Whether audiences will get behind The Lightnin...</td>\n",
       "      <td>4</td>\n",
       "      <td>audience Lightning Thief hard predict Overall ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m/0878835</td>\n",
       "      <td>Please Give</td>\n",
       "      <td>Nicole Holofcener's newest might seem slight i...</td>\n",
       "      <td>3/4</td>\n",
       "      <td>Holofcener always gives us more to chew on tha...</td>\n",
       "      <td>4</td>\n",
       "      <td>Holofcener give chew originally meet film writ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m/10</td>\n",
       "      <td>10</td>\n",
       "      <td>Blake Edwards' bawdy comedy may not score a pe...</td>\n",
       "      <td>4/5</td>\n",
       "      <td>Obvious but entertaining portrayal of midlife ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Obvious entertain portrayal midlife crisis go ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m/1000013-12_angry_men</td>\n",
       "      <td>12 Angry Men (Twelve Angry Men)</td>\n",
       "      <td>Sidney Lumet's feature debut is a superbly wri...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>In a time of bloated when special effects have...</td>\n",
       "      <td>5</td>\n",
       "      <td>time bloat special effect real star go classic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m/1000079-20000_leagues_under_the_sea</td>\n",
       "      <td>20,000 Leagues Under The Sea</td>\n",
       "      <td>One of Disney's finest live-action adventures,...</td>\n",
       "      <td>7/10</td>\n",
       "      <td>[The] embodiment of Disney at his best -- fami...</td>\n",
       "      <td>4</td>\n",
       "      <td>embodiment Disney well family entertainment su...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    rotten_tomatoes_link  \\\n",
       "0                              m/0814255   \n",
       "1                              m/0878835   \n",
       "2                                   m/10   \n",
       "3                 m/1000013-12_angry_men   \n",
       "4  m/1000079-20000_leagues_under_the_sea   \n",
       "\n",
       "                                         movie_title  \\\n",
       "0  Percy Jackson & the Olympians: The Lightning T...   \n",
       "1                                        Please Give   \n",
       "2                                                 10   \n",
       "3                    12 Angry Men (Twelve Angry Men)   \n",
       "4                       20,000 Leagues Under The Sea   \n",
       "\n",
       "                                   critics_consensus review_score  \\\n",
       "0  Though it may seem like just another Harry Pot...        3.5/5   \n",
       "1  Nicole Holofcener's newest might seem slight i...          3/4   \n",
       "2  Blake Edwards' bawdy comedy may not score a pe...          4/5   \n",
       "3  Sidney Lumet's feature debut is a superbly wri...          4/4   \n",
       "4  One of Disney's finest live-action adventures,...         7/10   \n",
       "\n",
       "                                      review_content  Standard_rating  \\\n",
       "0  Whether audiences will get behind The Lightnin...                4   \n",
       "1  Holofcener always gives us more to chew on tha...                4   \n",
       "2  Obvious but entertaining portrayal of midlife ...                4   \n",
       "3  In a time of bloated when special effects have...                5   \n",
       "4  [The] embodiment of Disney at his best -- fami...                4   \n",
       "\n",
       "                                  PreProcessedReview  \n",
       "0  audience Lightning Thief hard predict Overall ...  \n",
       "1  Holofcener give chew originally meet film writ...  \n",
       "2  Obvious entertain portrayal midlife crisis go ...  \n",
       "3  time bloat special effect real star go classic...  \n",
       "4  embodiment Disney well family entertainment su...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balancing Dataset by removing the Movies which has rating 0 and 1 \n",
    "# since the number of movies available for each of the rating is very less\n",
    "newDf = newDf[newDf.Standard_rating != 0]\n",
    "newDf = newDf[newDf.Standard_rating != 1]\n",
    "newDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancing the Dataset such that there are equal(almost equal) number of movies for each rating\n",
    "g = newDf.groupby('Standard_rating')\n",
    "bal_data = g.apply(lambda x: x.sample(g.size().min()).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_rating(rating):\n",
    "    rating = int(rating)\n",
    "    if rating <= 3:\n",
    "        return 0\n",
    "    else: \n",
    "        return 1\n",
    "\n",
    "# Reassigning the ratings of movies <=3 to 0 and 4-5 to 1(Multilabel to Binary Label) because for BERT outputs softmax probability for each rating\n",
    "# and in order to pick the maximum probablity index.\n",
    "\n",
    "bal_data['Standard_rating'] = bal_data.Standard_rating.apply(std_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviews = bal_data.PreProcessedReview.values\n",
    "reviews = bal_data.review_content.values\n",
    "labels = bal_data.Standard_rating.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_sentences, validation_sentences, train_labels, validation_labels = train_test_split(reviews, labels, \n",
    "                                                                                          test_size=0.2, \n",
    "                                                                                          stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.65      0.63      1226\n",
      "           1       0.63      0.58      0.60      1225\n",
      "\n",
      "    accuracy                           0.62      2451\n",
      "   macro avg       0.62      0.62      0.62      2451\n",
      "weighted avg       0.62      0.62      0.62      2451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "pipe_LR = Pipeline([('countvectorizer', vectorizer),('LR',LogisticRegression())])\n",
    "pipe_LR.fit(train_sentences, train_labels)\n",
    "pred_LR = pipe_LR.predict(validation_sentences)\n",
    "print(classification_report(validation_labels, pred_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.78      0.66      1226\n",
      "           1       0.65      0.42      0.51      1225\n",
      "\n",
      "    accuracy                           0.60      2451\n",
      "   macro avg       0.61      0.60      0.58      2451\n",
      "weighted avg       0.61      0.60      0.58      2451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "pipe_SVC = Pipeline([('countvectorizer', vectorizer),('SVC',SVC())])\n",
    "pipe_SVC.fit(train_sentences, train_labels)\n",
    "pred_SVC = pipe_SVC.predict(validation_sentences)\n",
    "print(classification_report(validation_labels, pred_SVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.73      0.62      1226\n",
      "           1       0.58      0.38      0.46      1225\n",
      "\n",
      "    accuracy                           0.55      2451\n",
      "   macro avg       0.56      0.55      0.54      2451\n",
      "weighted avg       0.56      0.55      0.54      2451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "pipe_DT = Pipeline([('countvectorizer', vectorizer),('decisiontree',DecisionTreeClassifier(max_depth=50))])\n",
    "pipe_DT.fit(train_sentences, train_labels)\n",
    "pred_DT = pipe_DT.predict(validation_sentences)\n",
    "print(classification_report(validation_labels, pred_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd459564e10>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot of length of reviews\n",
    "senlen = [len(train_sentences[i]) for i in range(len(train_sentences))]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(np.arange(len(senlen)),senlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import pandas as pd\n",
    "import torch\n",
    "#from pytorch_pretrained_bert import BertModel\n",
    "from torch import nn\n",
    "#from pytorch_pretrained_bert import BertTokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.optim import Adam\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (3.5.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.10)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.7/site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: tokenizers==0.9.3 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.9.3)\n",
      "Requirement already satisfied: sentencepiece==0.1.91 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers) (20.1)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.45.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2020.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (1.14.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (1.14.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (1.14.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.45.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2020.4.4)\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a149c394c9fd41bca012145e801a7fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing inputs and adding special tokens\n",
    "def input_id(input_review):\n",
    "    input_ids = []\n",
    "    MAX_LEN = 256\n",
    "    for r in input_review:\n",
    "        encoded_sent = tokenizer.encode(\n",
    "                        r,                      # Sentence which are encoding.\n",
    "                        add_special_tokens = True) # Adding special tokens '[CLS]' and '[SEP]'\n",
    "        input_ids.append(encoded_sent)\n",
    "    return input_ids\n",
    "train_id = input_id(train_sentences)\n",
    "val_id = input_id(validation_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding the Tokenized IDs\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "padded_train_id = pad_sequences(train_id, maxlen=256 , truncating=\"post\", padding=\"post\")\n",
    "padded_val_id = pad_sequences(val_id, maxlen=256 , truncating=\"post\", padding=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masking the padded ID's\n",
    "\n",
    "def masking(pid):\n",
    "    attention_masks = []\n",
    "\n",
    "    for r in pid:\n",
    "    \n",
    "        # Generating attention mask for sentences.\n",
    "        #   - when there is 0 present as token id we are going to set mask as 0.\n",
    "        #   - we are going to set mask 1 for all non-zero positive input id.\n",
    "        att_mask = [int(token_id > 0) for token_id in r]\n",
    "        attention_masks.append(att_mask)\n",
    "\n",
    "    return attention_masks\n",
    "\n",
    "train_mask = masking(padded_train_id)\n",
    "val_mask = masking(padded_val_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the numpy arrays into tensors for working on GPU.\n",
    "import torch\n",
    "\n",
    "tr_inputs = torch.tensor(padded_train_id)\n",
    "val_inputs = torch.tensor(padded_val_id)\n",
    "\n",
    "tr_labels = torch.tensor(train_labels.reshape(-1, 1)).float()\n",
    "val_labels = torch.tensor(validation_labels.reshape(-1, 1)).float()\n",
    "\n",
    "tr_masks = torch.tensor(train_mask)\n",
    "val_masks = torch.tensor(val_mask)\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Deciding the batch size for training.\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "#DataLoader for our training set.\n",
    "train_data = TensorDataset(tr_inputs, tr_masks, tr_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# DataLoader for our validation(test) set.\n",
    "validation_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building custom BERT model with additional Classification layer\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes = 2):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.out = nn.Linear(768, n_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "  \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \n",
    "        _, pooled_output = self.bert(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "    )\n",
    "        output = self.drop(pooled_output)\n",
    "        #print(torch.max(output,dim = 1))\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for GPU processors\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "\n",
    "torch.cuda.empty_cache()     # Clearing Cache space for fresh Model run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c66df49f04c47dd98db574db6159f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d693cf468ab74252aa05d8ced122f48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Assigning model to GPU\n",
    "model = BertClassifier()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=3e-6)\n",
    "total_steps = len(train_dataloader) * EPOCHS\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5\n",
      "\r",
      "1225/1225.125 loss: 0.5042241331445111 \n"
     ]
    }
   ],
   "source": [
    "# Training the Model\n",
    "\n",
    "for epoch_num in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for step_num, batch_data in enumerate(train_dataloader):\n",
    "        token_ids, masks, targets = tuple(t.to(device).long() for t in batch_data)\n",
    "\n",
    "        outputs = model(\n",
    "      token_ids,\n",
    "      masks\n",
    "    )\n",
    "        #print(len(targets))\n",
    "        targets = targets.reshape((1,len(targets)))\n",
    "\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        loss = loss_fn(outputs, targets[0])\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "\n",
    "        clip_grad_norm_(parameters=model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        print('Epoch: ', epoch_num + 1)\n",
    "        print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(train_data) / batch_size, train_loss / (step_num + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating and Predicting the Movie Ratings for Validation data\n",
    "\n",
    "model.eval()\n",
    "bert_predicted = []\n",
    "with torch.no_grad():\n",
    "    for step_num, batch_data in enumerate(validation_dataloader):\n",
    "        token_ids, masks, targets = tuple(t.to(device).long() for t in batch_data)\n",
    "\n",
    "        outputs = model(\n",
    "      token_ids,\n",
    "      masks\n",
    "    )\n",
    "        \n",
    "        targets = targets.reshape((1,len(targets)))\n",
    "\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        bert_predicted.append(preds)\n",
    "    \n",
    "pred = []\n",
    "for i in range(len(bert_predicted)):\n",
    "    for j in range(len(bert_predicted[i])):\n",
    "        pred.append(bert_predicted[i][j])\n",
    "    \n",
    "pred = torch.tensor(pred).numpy()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.53      0.60      1226\n",
      "         1.0       0.62      0.76      0.68      1225\n",
      "\n",
      "    accuracy                           0.64      2451\n",
      "   macro avg       0.65      0.64      0.64      2451\n",
      "weighted avg       0.65      0.64      0.64      2451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val_labels, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below code is used only for miscellaneous comparison of accuracies with Word Emedding, LSTM, GRU and Glove Embedding models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize sentences\n",
    "tokenizer = Tokenizer(num_words = 1500)\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# convert train dataset to sequence and pad sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "train_padded = pad_sequences(train_sequences, padding='post', maxlen=120)\n",
    "\n",
    "# convert validation dataset to sequence and pad sequences\n",
    "validation_sequences = tokenizer.texts_to_sequences(validation_sentences)\n",
    "validation_padded = pad_sequences(validation_sequences, padding='post', maxlen=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 120, 100)          1591200   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 24)                2424      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 1,593,649\n",
      "Trainable params: 1,593,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Word Embedding\n",
    "\n",
    "# model initialization\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(word_index), output_dim= 100, input_length=120),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "245/245 - 4s - loss: 0.6932 - accuracy: 0.5043 - val_loss: 0.6929 - val_accuracy: 0.5135\n",
      "Epoch 2/10\n",
      "245/245 - 3s - loss: 0.6930 - accuracy: 0.5068 - val_loss: 0.6927 - val_accuracy: 0.5135\n",
      "Epoch 3/10\n",
      "245/245 - 3s - loss: 0.6926 - accuracy: 0.5157 - val_loss: 0.6925 - val_accuracy: 0.4870\n",
      "Epoch 4/10\n",
      "245/245 - 3s - loss: 0.6882 - accuracy: 0.5575 - val_loss: 0.6853 - val_accuracy: 0.5446\n",
      "Epoch 5/10\n",
      "245/245 - 4s - loss: 0.6593 - accuracy: 0.6298 - val_loss: 0.6595 - val_accuracy: 0.6226\n",
      "Epoch 6/10\n",
      "245/245 - 4s - loss: 0.6139 - accuracy: 0.6728 - val_loss: 0.6495 - val_accuracy: 0.6262\n",
      "Epoch 7/10\n",
      "245/245 - 4s - loss: 0.5848 - accuracy: 0.6909 - val_loss: 0.6554 - val_accuracy: 0.6232\n",
      "Epoch 8/10\n",
      "245/245 - 4s - loss: 0.5656 - accuracy: 0.7096 - val_loss: 0.6598 - val_accuracy: 0.6262\n",
      "Epoch 9/10\n",
      "245/245 - 3s - loss: 0.5587 - accuracy: 0.7134 - val_loss: 0.6667 - val_accuracy: 0.6283\n",
      "Epoch 10/10\n",
      "245/245 - 4s - loss: 0.5504 - accuracy: 0.7147 - val_loss: 0.6848 - val_accuracy: 0.6130\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "num_epochs = 10\n",
    "history = model.fit(train_padded, train_labels, \n",
    "                    epochs=num_epochs, verbose=2, \n",
    "                    validation_split=0.2)\n",
    "\n",
    "# predict values\n",
    "pred = model.predict(validation_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.53      0.58      1226\n",
      "           1       0.59      0.68      0.63      1225\n",
      "\n",
      "    accuracy                           0.61      2451\n",
      "   macro avg       0.61      0.61      0.60      2451\n",
      "weighted avg       0.61      0.61      0.60      2451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = [1 if i > 0.5 else 0 for i in pred]\n",
    "print(classification_report(validation_labels, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 120, 100)          1591200   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 120, 128)          84480     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                41216     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                1560      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 1,718,481\n",
      "Trainable params: 1,718,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM\n",
    "model1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(word_index), output_dim= 100, input_length=120),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# compile model\n",
    "model1.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "245/245 - 10s - loss: 0.6727 - accuracy: 0.5760 - val_loss: 0.6569 - val_accuracy: 0.6165\n",
      "Epoch 2/10\n",
      "245/245 - 8s - loss: 0.5992 - accuracy: 0.6810 - val_loss: 0.6611 - val_accuracy: 0.6114\n",
      "Epoch 3/10\n",
      "245/245 - 9s - loss: 0.5452 - accuracy: 0.7309 - val_loss: 0.6980 - val_accuracy: 0.6084\n",
      "Epoch 4/10\n",
      "245/245 - 9s - loss: 0.5011 - accuracy: 0.7545 - val_loss: 0.7414 - val_accuracy: 0.5895\n",
      "Epoch 5/10\n",
      "245/245 - 8s - loss: 0.4611 - accuracy: 0.7865 - val_loss: 0.8686 - val_accuracy: 0.5839\n",
      "Epoch 6/10\n",
      "245/245 - 8s - loss: 0.4192 - accuracy: 0.8098 - val_loss: 0.8899 - val_accuracy: 0.5778\n",
      "Epoch 7/10\n",
      "245/245 - 8s - loss: 0.3776 - accuracy: 0.8293 - val_loss: 0.9513 - val_accuracy: 0.5931\n",
      "Epoch 8/10\n",
      "245/245 - 8s - loss: 0.3295 - accuracy: 0.8509 - val_loss: 1.1621 - val_accuracy: 0.5793\n",
      "Epoch 9/10\n",
      "245/245 - 8s - loss: 0.2877 - accuracy: 0.8622 - val_loss: 1.2565 - val_accuracy: 0.5701\n",
      "Epoch 10/10\n",
      "245/245 - 8s - loss: 0.2476 - accuracy: 0.8828 - val_loss: 1.3770 - val_accuracy: 0.5854\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "num_epochs = 10\n",
    "history1 = model1.fit(train_padded, train_labels, \n",
    "                    epochs=num_epochs, verbose=2, \n",
    "                    validation_split=0.2)\n",
    "\n",
    "# predict values\n",
    "pred1 = model1.predict(validation_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.61      0.58      1226\n",
      "           1       0.57      0.52      0.54      1225\n",
      "\n",
      "    accuracy                           0.57      2451\n",
      "   macro avg       0.57      0.57      0.56      2451\n",
      "weighted avg       0.57      0.57      0.56      2451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred1 = [1 if i > 0.5 else 0 for i in pred1]\n",
    "print(classification_report(validation_labels, pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 120, 100)          1591200   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 128)               63744     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 24)                3096      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 1,658,065\n",
      "Trainable params: 1,658,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GRU\n",
    "\n",
    "model3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(word_index), output_dim= 100, input_length=120),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64)),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# compile model\n",
    "model3.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "245/245 - 6s - loss: 0.6738 - accuracy: 0.5698 - val_loss: 0.6645 - val_accuracy: 0.6002\n",
      "Epoch 2/10\n",
      "245/245 - 6s - loss: 0.6009 - accuracy: 0.6753 - val_loss: 0.6680 - val_accuracy: 0.6068\n",
      "Epoch 3/10\n",
      "245/245 - 6s - loss: 0.5464 - accuracy: 0.7202 - val_loss: 0.6884 - val_accuracy: 0.5992\n",
      "Epoch 4/10\n",
      "245/245 - 6s - loss: 0.4926 - accuracy: 0.7511 - val_loss: 0.7681 - val_accuracy: 0.5778\n",
      "Epoch 5/10\n",
      "245/245 - 6s - loss: 0.4390 - accuracy: 0.7824 - val_loss: 0.8735 - val_accuracy: 0.5839\n",
      "Epoch 6/10\n",
      "245/245 - 6s - loss: 0.3770 - accuracy: 0.8119 - val_loss: 1.0145 - val_accuracy: 0.5716\n",
      "Epoch 7/10\n",
      "245/245 - 6s - loss: 0.3260 - accuracy: 0.8370 - val_loss: 1.1451 - val_accuracy: 0.5722\n",
      "Epoch 8/10\n",
      "245/245 - 6s - loss: 0.2774 - accuracy: 0.8543 - val_loss: 1.3921 - val_accuracy: 0.5604\n",
      "Epoch 9/10\n",
      "245/245 - 6s - loss: 0.2468 - accuracy: 0.8732 - val_loss: 1.6519 - val_accuracy: 0.5609\n",
      "Epoch 10/10\n",
      "245/245 - 6s - loss: 0.2086 - accuracy: 0.8897 - val_loss: 1.8792 - val_accuracy: 0.5609\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "num_epochs = 10\n",
    "history3 = model3.fit(train_padded, train_labels, \n",
    "                    epochs=num_epochs, verbose=2, \n",
    "                    validation_split=0.2)\n",
    "\n",
    "# predict values\n",
    "pred3 = model3.predict(validation_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.58      0.57      1226\n",
      "           1       0.56      0.54      0.55      1225\n",
      "\n",
      "    accuracy                           0.56      2451\n",
      "   macro avg       0.56      0.56      0.56      2451\n",
      "weighted avg       0.56      0.56      0.56      2451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred3 = [1 if i > 0.5 else 0 for i in pred3]\n",
    "print(classification_report(validation_labels, pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "with open('/kaggle/input/glove-embeddings/glove.6B.100d.txt') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "embeddings_matrix = np.zeros((len(word_index) + 1, 100))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embeddings_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 120, 100)          1591300   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 24)                2424      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 1,593,749\n",
      "Trainable params: 2,449\n",
      "Non-trainable params: 1,591,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model initialization\n",
    "model4 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(word_index)+1, output_dim= 100, input_length=120, weights=[embeddings_matrix], trainable=False),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# compile model\n",
    "model4.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "model4.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "245/245 - 1s - loss: 0.6911 - accuracy: 0.5263 - val_loss: 0.6877 - val_accuracy: 0.5553\n",
      "Epoch 2/10\n",
      "245/245 - 1s - loss: 0.6831 - accuracy: 0.5774 - val_loss: 0.6800 - val_accuracy: 0.5706\n",
      "Epoch 3/10\n",
      "245/245 - 1s - loss: 0.6756 - accuracy: 0.5834 - val_loss: 0.6746 - val_accuracy: 0.5727\n",
      "Epoch 4/10\n",
      "245/245 - 1s - loss: 0.6699 - accuracy: 0.5918 - val_loss: 0.6732 - val_accuracy: 0.5722\n",
      "Epoch 5/10\n",
      "245/245 - 1s - loss: 0.6664 - accuracy: 0.5954 - val_loss: 0.6698 - val_accuracy: 0.5778\n",
      "Epoch 6/10\n",
      "245/245 - 1s - loss: 0.6637 - accuracy: 0.5964 - val_loss: 0.6719 - val_accuracy: 0.5844\n",
      "Epoch 7/10\n",
      "245/245 - 1s - loss: 0.6615 - accuracy: 0.6024 - val_loss: 0.6654 - val_accuracy: 0.5834\n",
      "Epoch 8/10\n",
      "245/245 - 1s - loss: 0.6597 - accuracy: 0.6055 - val_loss: 0.6651 - val_accuracy: 0.5880\n",
      "Epoch 9/10\n",
      "245/245 - 1s - loss: 0.6576 - accuracy: 0.6091 - val_loss: 0.6641 - val_accuracy: 0.5864\n",
      "Epoch 10/10\n",
      "245/245 - 1s - loss: 0.6568 - accuracy: 0.6074 - val_loss: 0.6651 - val_accuracy: 0.5905\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "num_epochs = 10\n",
    "history4 = model4.fit(train_padded, train_labels, \n",
    "                    epochs=num_epochs, verbose=2, \n",
    "                    validation_split=0.2)\n",
    "\n",
    "# predict values\n",
    "pred4 = model4.predict(validation_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.60      0.59      1226\n",
      "           1       0.59      0.56      0.58      1225\n",
      "\n",
      "    accuracy                           0.58      2451\n",
      "   macro avg       0.58      0.58      0.58      2451\n",
      "weighted avg       0.58      0.58      0.58      2451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred4 = [1 if i >= 0.5 else 0 for i in pred4]\n",
    "print(classification_report(validation_labels, pred4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
